[rank: 0] Seed set to 42
wandb: Currently logged in as: jc200108 (koes-group). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in ./wandb/run-20250618_214129-fnsl1pc8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run self_conditioning
wandb: ‚≠êÔ∏è View project at https://wandb.ai/koes-group/omtra
wandb: üöÄ View run at https://wandb.ai/koes-group/omtra/runs/fnsl1pc8
/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python routines/train.py num_workers=16 name=self_condition ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA L40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                  | Type                 | Params | Mode 
-----------------------------------------------------------------------
0 | interpolant_scheduler | InterpolantScheduler | 0      | train
1 | vector_field          | VectorField          | 3.4 M  | train
-----------------------------------------------------------------------
3.4 M     Trainable params
0         Non-trainable params
3.4 M     Total params
13.422    Total estimated model params size (MB)
365       Modules in train mode
0         Modules in eval mode
‚öõ Instantiating datamodule <omtra.dataset.data_module.MultiTaskDataModule>
‚öõ Instantiating model <omtra.models.omtra.OMTRA>
Warning: no wandb run found. Setting previous sample counts to 0.
Instantiating callback <pytorch_lightning.callbacks.TQDMProgressBar>
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Error executing job with overrides: ['num_workers=16', 'name=self_conditioning', 'task_group=pharmit5050', 'edges_per_batch=400000', 'trainer.val_check_interval=600', 'max_steps=300000', 'trainer.limit_val_batches=2', 'model.vector_field.convs_per_update=1', 'model.vector_field.n_molecule_updates=4', 'pharmit_path=/net/galaxy/home/koes/icd3/moldiff/OMTRA/data/pharmit', 'pharmit_library_conditioning=True', 'plinder_path=/net/galaxy/home/koes/tjkatz/OMTRA/data/plinder']
Traceback (most recent call last):
  File "/net/galaxy/home/koes/jmc530/OMTRA/routines/train.py", line 184, in main
    _ = train(cfg)
        ^^^^^^^^^^
  File "/net/galaxy/home/koes/jmc530/OMTRA/routines/train.py", line 152, in train
    trainer.fit(model, datamodule=datamodule, ckpt_path=cfg.get("checkpoint"))
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 539, in fit
    call._call_and_handle_interrupt(
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 575, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 982, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1024, in _run_stage
    self._run_sanity_check()
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run_sanity_check
    val_loop.run()
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 144, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 433, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 323, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/net/dali/home/mscbio/jmc530/OMTRA/omtra/models/omtra.py", line 302, in validation_step
    samples = self.sample(task_name, g_list=g_list, n_replicates=n_replicates, n_timesteps=200, device=device, coms=coms,sys_data=sys_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/net/dali/home/mscbio/jmc530/OMTRA/omtra/models/omtra.py", line 718, in sample
    itg_result = self.vector_field.integrate(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/net/dali/home/mscbio/jmc530/OMTRA/omtra/models/vector_field.py", line 864, in integrate
    g, dst_dict = self.step(
                  ^^^^^^^^^^
  File "/net/dali/home/mscbio/jmc530/OMTRA/omtra/models/vector_field.py", line 1020, in step
    logits_guided = x_u + self.cfg_scale * (x_c - x_u)
                          ^^^^^^^^^^^^^^
  File "/net/galaxy/home/koes/jmc530/.conda/envs/omtra/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1729, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'VectorField' object has no attribute 'cfg_scale'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mself_conditioning[0m at: [34mhttps://wandb.ai/koes-group/omtra/runs/fnsl1pc8[0m
                                                                   