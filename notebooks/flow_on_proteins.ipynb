{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f3b32f-6c76-4ea5-921a-6c1586badb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install Bio\n",
    "# %pip install geoopt\n",
    "# %pip install flow_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605f488a-442e-412c-9f66-5b2f0c52086b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import nn, Tensor\n",
    "\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "# from geoopt import Euclidean\n",
    "\n",
    "from flow_matching.path import GeodesicProbPath\n",
    "from flow_matching.path.scheduler import CondOTScheduler\n",
    "from flow_matching.solver import ODESolver, RiemannianODESolver\n",
    "from flow_matching.utils import ModelWrapper\n",
    "from flow_matching.utils.manifolds import FlatTorus, Manifold\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    print('Using gpu')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Using cpu.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e8f422e-fc7d-45a7-9af6-6f221223070a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone rotation (R_frame_torch):\n",
      " tensor([[-0.8000,  0.6000,  0.0000],\n",
      "        [ 0.6000,  0.8000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.0000]])\n",
      "Backbone origin (t_frame_torch):\n",
      " tensor([0.0000, 1.2000, 0.0000])\n",
      "C-alpha coordinate: tensor([0.0000, 1.2000, 0.0000])\n",
      "Chi angles (radians): tensor([-0.6559, -1.7392, -3.1416, -3.1416])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -- 1) LOAD SINGLE-RESIDUE LYSINE FROM PDB --\n",
    "pdb_parser = PDBParser(QUIET=True)\n",
    "structure = pdb_parser.get_structure(\"lys\", \"lysine.pdb\")\n",
    "\n",
    "# Assume there's exactly one model, one chain, one residue\n",
    "model = structure[0]\n",
    "chain = next(model.get_chains())\n",
    "res = next(chain.get_residues())\n",
    "\n",
    "# -- 2) EXTRACT BACKBONE ATOMS & BUILD LOCAL BACKBONE FRAME --\n",
    "\n",
    "# Grab coordinates of N, CA, and C\n",
    "N_coord  = np.array(res[\"N\"].coord)\n",
    "CA_coord = np.array(res[\"CA\"].coord)\n",
    "C_coord  = np.array(res[\"C\"].coord)\n",
    "\n",
    "def build_backbone_frame(N, CA, C):\n",
    "    \"\"\"\n",
    "    Build a local coordinate frame (3x3 rotation + origin) from \n",
    "    the backbone atoms N, CA, C.\n",
    "\n",
    "    One common convention:\n",
    "    - Origin = CA\n",
    "    - x-axis = (CA -> C) normalized\n",
    "    - y-axis = projection of (CA -> N) orthogonal to x, then normalized\n",
    "    - z-axis = x cross y\n",
    "    Returns:\n",
    "       R (3x3 np.array) - rotation matrix\n",
    "       t (3, )          - translation (the CA coordinates)\n",
    "    \"\"\"\n",
    "    # Origin at CA\n",
    "    origin = CA\n",
    "\n",
    "    # x-axis: from CA to C (normalized)\n",
    "    x = C - CA\n",
    "    x /= np.linalg.norm(x)\n",
    "\n",
    "    # provisional y-axis: from CA to N\n",
    "    y = N - CA\n",
    "    # remove component along x\n",
    "    y -= (np.dot(y, x) * x)\n",
    "    y /= np.linalg.norm(y)\n",
    "\n",
    "    # z-axis: cross(x, y)\n",
    "    z = np.cross(x, y)\n",
    "    z /= np.linalg.norm(z)\n",
    "\n",
    "    R = np.stack([x, y, z], axis=1)  # shape (3, 3)\n",
    "    t = origin\n",
    "    return R, t\n",
    "\n",
    "R_frame, t_frame = build_backbone_frame(N_coord, CA_coord, C_coord)\n",
    "\n",
    "# Convert to torch tensors\n",
    "R_frame_torch = torch.tensor(R_frame, dtype=torch.float32)  # (3x3)\n",
    "t_frame_torch = torch.tensor(t_frame, dtype=torch.float32)  # (3,)\n",
    "\n",
    "# -- 3) EXTRACT CA COORDINATES (as Torch tensor) --\n",
    "ca_torch = torch.tensor(CA_coord, dtype=torch.float32)\n",
    "\n",
    "# -- 4) COMPUTE SIDECHAIN CHI ANGLES FOR LYS --\n",
    "# Lys sidechain atoms: \n",
    "#    χ1: N - CA - CB - CG\n",
    "#    χ2: CA - CB - CG - CD\n",
    "#    χ3: CB - CG - CD - CE\n",
    "#    χ4: CG - CD - CE - NZ\n",
    "\n",
    "def dihedral_angle(a, b, c, d):\n",
    "    \"\"\"\n",
    "    Compute dihedral angle in radians for four points \n",
    "    (each one is an np.array of shape (3,)).\n",
    "    Formula based on cross/cross method.\n",
    "    \"\"\"\n",
    "    b1 = b - a\n",
    "    b2 = c - b\n",
    "    b3 = d - c\n",
    "    \n",
    "    # normal to plane 1\n",
    "    n1 = np.cross(b1, b2)\n",
    "    # normal to plane 2\n",
    "    n2 = np.cross(b2, b3)\n",
    "    \n",
    "    # normalize\n",
    "    n1 /= np.linalg.norm(n1)\n",
    "    n2 /= np.linalg.norm(n2)\n",
    "    \n",
    "    # direction of b2 for sign of angle\n",
    "    m1 = np.cross(n1, b2 / np.linalg.norm(b2))\n",
    "    x = np.dot(n1, n2)\n",
    "    y = np.dot(m1, n2)\n",
    "    angle = -math.atan2(y, x)  # negative to match common convention\n",
    "    return angle\n",
    "\n",
    "atom_names = [\"N\",\"CA\",\"CB\",\"CG\",\"CD\",\"CE\",\"NZ\"]\n",
    "coords = {an: np.array(res[an].coord) for an in atom_names}\n",
    "\n",
    "chi1 = dihedral_angle(coords[\"N\"],  coords[\"CA\"], coords[\"CB\"], coords[\"CG\"])\n",
    "chi2 = dihedral_angle(coords[\"CA\"], coords[\"CB\"], coords[\"CG\"], coords[\"CD\"])\n",
    "chi3 = dihedral_angle(coords[\"CB\"], coords[\"CG\"], coords[\"CD\"], coords[\"CE\"])\n",
    "chi4 = dihedral_angle(coords[\"CG\"], coords[\"CD\"], coords[\"CE\"], coords[\"NZ\"])\n",
    "\n",
    "# Store sidechain chi angles in a torch tensor (radians)\n",
    "chi_torch = torch.tensor([chi1, chi2, chi3, chi4], dtype=torch.float32)\n",
    "\n",
    "# -- 5) Print or use the results --\n",
    "print(\"Backbone rotation (R_frame_torch):\\n\", R_frame_torch)\n",
    "print(\"Backbone origin (t_frame_torch):\\n\", t_frame_torch)\n",
    "print(\"C-alpha coordinate:\", ca_torch)\n",
    "print(\"Chi angles (radians):\", chi_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb44e67b-226c-4544-98c5-3cca70ad9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierFeatures(nn.Module):\n",
    "    \"\"\"Assumes input is in [0, 2pi].\"\"\"\n",
    "\n",
    "    def __init__(self, n_fourier_features: int):\n",
    "        super().__init__()\n",
    "        self.n_fourier_features = n_fourier_features\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        feature_vector = [\n",
    "            torch.sin((i + 1) * x) for i in range(self.n_fourier_features)\n",
    "        ]\n",
    "        feature_vector += [\n",
    "            torch.cos((i + 1) * x) for i in range(self.n_fourier_features)\n",
    "        ]\n",
    "        return torch.cat(feature_vector, dim=-1)\n",
    "\n",
    "\n",
    "class ProjectToTangent(nn.Module):\n",
    "    \"\"\"Projects a vector field onto the tangent plane at the input.\"\"\"\n",
    "\n",
    "    def __init__(self, vecfield: nn.Module, manifold: Manifold):\n",
    "        super().__init__()\n",
    "        self.vecfield = vecfield\n",
    "        self.manifold = manifold\n",
    "\n",
    "    def forward(self, x: Tensor, t: Tensor) -> Tensor:\n",
    "        x = self.manifold.projx(x)\n",
    "        v = self.vecfield(x, t)\n",
    "        v = self.manifold.proju(x, v)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "204b08c5-0f31-4ee1-bbb6-2ef02256e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Let's define a 2-layer MLP that:\n",
    "# (1) has an input dimension of 16\n",
    "# (2) has a hidden dimension (e.g. 32)\n",
    "# (3) outputs dimension 16\n",
    "\n",
    "class BackboneNet(nn.Module):\n",
    "    def __init__(self, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, hidden_dim)  # fully-connected layer 1\n",
    "        self.fc2 = nn.Linear(hidden_dim, 16)  # fully-connected layer 2\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 16)\n",
    "        h = self.fc1(x)         # shape: (batch_size, hidden_dim)\n",
    "        h = self.relu(h)\n",
    "        out = self.fc2(h)       # shape: (batch_size, 16)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1767e048-73eb-4411-bd91-9b70d8e8be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_train_gen(backbone_coords, frame,chi_angles,batch_size: int = 200, device: str = \"cpu\"):\n",
    "    random_backbone = torch.randn((batch_size, backbone_coords.shape),3, device=device)\n",
    "    random_frame = (torch.randn((batch_size,frame.shape), device=device)) #TODO cap these some how\n",
    "    random_chi_angles = torch.randn((batch_size,frame.shape), device=device)\n",
    "\n",
    "    return random_backbone, random_frame, random_chi_angles\n",
    "\n",
    "def wrap(manifold, samples):\n",
    "    center = torch.zeros_like(samples)\n",
    "\n",
    "    return manifold.expmap(center, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6a8c7f0-4210-4bb4-9ed2-cd2f8717a372",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randn() received an invalid combination of arguments - got (tuple, int, device=str), but expected one of:\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad() \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# sample data (user's responsibility): in this case, (X_0,X_1) ~ pi(X_0,X_1) = N(X_0|0,I)q(X_1)\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m x_0_t, x_0_r , x_0_chi \u001b[38;5;241m=\u001b[39m \u001b[43minf_train_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_frame_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mR_frame_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchi_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# sample data\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# sample time (user's responsibility)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(x_1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device) \n",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m, in \u001b[0;36minf_train_gen\u001b[0;34m(backbone_coords, frame, chi_angles, batch_size, device)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minf_train_gen\u001b[39m(backbone_coords, frame,chi_angles,batch_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m, device: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     random_backbone \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackbone_coords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     random_frame \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mrandn((batch_size,frame\u001b[38;5;241m.\u001b[39mshape), device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;66;03m#TODO cap these some how\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     random_chi_angles \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((batch_size,frame\u001b[38;5;241m.\u001b[39mshape), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mTypeError\u001b[0m: randn() received an invalid combination of arguments - got (tuple, int, device=str), but expected one of:\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "source": [
    "# training arguments\n",
    "lr = 0.001\n",
    "batch_size = 4096\n",
    "iterations = 5001\n",
    "print_every = 1000\n",
    "manifold = FlatTorus()\n",
    "dim = 2\n",
    "hidden_dim = 16\n",
    "\n",
    "\n",
    "## TODO get rid of projectToTangent if we use RCFM loss and a geodesic map?\n",
    "# velocity field model init\n",
    "vf = ProjectToTangent(  # Ensures we can just use Euclidean divergence.\n",
    "    BackboneNet(  # Vector field in the ambient space.\n",
    "        hidden_dim=hidden_dim,\n",
    "    ),\n",
    "    manifold=manifold,\n",
    ")\n",
    "vf.to(device)\n",
    "\n",
    "# instantiate an affine path object\n",
    "# TODO add linear and SO3 paths\n",
    "path = GeodesicProbPath(scheduler=CondOTScheduler(), manifold=manifold)\n",
    "\n",
    "# init optimizer\n",
    "optim = torch.optim.Adam(vf.parameters(), lr=lr) \n",
    "\n",
    "# train\n",
    "start_time = time.time()\n",
    "for i in range(iterations):\n",
    "    optim.zero_grad() \n",
    "\n",
    "    # sample data (user's responsibility): in this case, (X_0,X_1) ~ pi(X_0,X_1) = N(X_0|0,I)q(X_1)\n",
    "    x_0_t, x_0_r , x_0_chi = inf_train_gen(t_frame_torch,R_frame_torch,chi_torch,batch_size=batch_size, device=device) # sample data\n",
    "\n",
    "    # sample time (user's responsibility)\n",
    "    t = torch.rand(x_1.shape[0]).to(device) \n",
    "\n",
    "    # sample probability path\n",
    "    path_sample = path.sample(t=t, x_0=x_0, x_1=x_1)\n",
    "\n",
    "    # flow matching l2 loss\n",
    "    loss = torch.pow( vf(path_sample.x_t,path_sample.t) - path_sample.dx_t, 2).mean()\n",
    "\n",
    "    # optimizer step\n",
    "    loss.backward() # backward\n",
    "    optim.step() # update\n",
    "    \n",
    "    # log loss\n",
    "    if (i+1) % print_every == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print('| iter {:6d} | {:5.2f} ms/step | loss {:8.3f} ' \n",
    "              .format(i+1, elapsed*1000/print_every, loss.item())) \n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87807a87-a3e8-4f1a-b2c2-2e9667c1ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierFeatures(nn.Module):\n",
    "    \"\"\"Assumes input is in [0, 2pi].\"\"\"\n",
    "\n",
    "    def __init__(self, n_fourier_features: int):\n",
    "        super().__init__()\n",
    "        self.n_fourier_features = n_fourier_features\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        feature_vector = [\n",
    "            torch.sin((i + 1) * x) for i in range(self.n_fourier_features)\n",
    "        ]\n",
    "        feature_vector += [\n",
    "            torch.cos((i + 1) * x) for i in range(self.n_fourier_features)\n",
    "        ]\n",
    "        return torch.cat(feature_vector, dim=-1)\n",
    "\n",
    "\n",
    "class ProjectToTangent(nn.Module):\n",
    "    \"\"\"Projects a vector field onto the tangent plane at the input.\"\"\"\n",
    "\n",
    "    def __init__(self, vecfield: nn.Module, manifold: Manifold):\n",
    "        super().__init__()\n",
    "        self.vecfield = vecfield\n",
    "        self.manifold = manifold\n",
    "\n",
    "    def forward(self, x: Tensor, t: Tensor) -> Tensor:\n",
    "        x = self.manifold.projx(x)\n",
    "        v = self.vecfield(x, t)\n",
    "        v = self.manifold.proju(x, v)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd70589-94ea-4df9-9b27-4a28122bb73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391fcc0-9198-403d-8043-d233717c62ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93c63b-7e4e-49f6-ad68-528c61964789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d03a36-ac03-482e-9474-a4a450cd8f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e58e6-9ca8-41e1-8e5c-cd20e7ceb219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5400957-46ab-43b5-9559-3ba7f19280d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd06ded-e428-4ada-9058-781c33d9d550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
