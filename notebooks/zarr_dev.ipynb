{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as torch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a single array, in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we're createing an in-memory zarr store but we could just as easily create a directory store and have the zarr array stored on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type               : Array\n",
       "Zarr format        : 3\n",
       "Data type          : DataType.float32\n",
       "Shape              : (1000, 100)\n",
       "Chunk shape        : (100, 100)\n",
       "Order              : C\n",
       "Read-only          : False\n",
       "Store type         : MemoryStore\n",
       "Filters            : ()\n",
       "Serializer         : BytesCodec(endian=<Endian.little: 'little'>)\n",
       "Compressors        : (ZstdCodec(level=0, checksum=False),)\n",
       "No. bytes          : 400000 (390.6K)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic example of creating and writing data to a zarr array\n",
    "n_rows, n_feats = 1000, 100\n",
    "\n",
    "z = zarr.create(shape=(n_rows, n_feats), \n",
    "                chunks=(100, n_feats), \n",
    "                dtype=\"f4\", \n",
    "                store=zarr.storage.MemoryStore())\n",
    "\n",
    "# Assign data to the array\n",
    "z[:, :] = np.random.random((n_rows, n_feats))\n",
    "z.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# writing a single molecule to a zarr store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake data for a single molecule\n",
    "n_atoms = 5\n",
    "n_bonds = 3\n",
    "positions = np.random.randn(n_atoms,3)\n",
    "atom_types = np.zeros(n_atoms, dtype=int)\n",
    "bond_orders = np.zeros(n_bonds, dtype=int)\n",
    "edge_idxs = np.random.randint(0, n_atoms, size=(n_bonds, 2))\n",
    "\n",
    "# Create a Zarr MemoryStore\n",
    "# in practice we'll use a DirectoryStore but for this educational example we'll use a MemoryStore\n",
    "store = zarr.storage.MemoryStore()\n",
    "\n",
    "# Create a root group\n",
    "root = zarr.group(store=store)\n",
    "\n",
    "# Store tensors under different keys with specified chunk sizes\n",
    "root.create_array('positions', shape=positions.shape, chunks=(1, 3), dtype=positions.dtype)\n",
    "root.create_array('atom_types', shape=atom_types.shape, chunks=(1,), dtype=atom_types.dtype)\n",
    "root.create_array('bond_orders', shape=bond_orders.shape, chunks=(1,), dtype=bond_orders.dtype)\n",
    "root.create_array('edge_idxs', shape=edge_idxs.shape, chunks=(1, 2), dtype=edge_idxs.dtype)\n",
    "\n",
    "# write data to the arrays\n",
    "root['positions'][:] = positions\n",
    "root['atom_types'][:] = atom_types\n",
    "root['bond_orders'][:] = bond_orders\n",
    "root['edge_idxs'][:] = edge_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions: [[-1.08603681 -1.71000467  0.40702887]\n",
      " [ 1.51526509  1.26331849  0.31723167]\n",
      " [ 0.98958225  0.93055011 -0.25018692]\n",
      " [ 0.35657579 -0.56742346  0.38875173]\n",
      " [-0.26366849 -0.09798329 -0.60565436]]\n",
      "Atom Types: [0 0 0 0 0]\n",
      "Bond Orders: [0 0 0]\n",
      "Edge Indices: [[0 2]\n",
      " [0 3]\n",
      " [2 1]]\n",
      "Positions chunk size: (1, 3)\n",
      "Atom Types chunk size: (1,)\n",
      "Bond Orders chunk size: (1,)\n",
      "Edge Indices chunk size: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Access data (same as before)\n",
    "print(\"Positions:\", root['positions'][:])\n",
    "print(\"Atom Types:\", root['atom_types'][:])\n",
    "print(\"Bond Orders:\", root['bond_orders'][:])\n",
    "print(\"Edge Indices:\", root['edge_idxs'][:])\n",
    "\n",
    "# Check chunk sizes\n",
    "print(\"Positions chunk size:\", root['positions'].chunks)\n",
    "print(\"Atom Types chunk size:\", root['atom_types'].chunks)\n",
    "print(\"Bond Orders chunk size:\", root['bond_orders'].chunks)\n",
    "print(\"Edge Indices chunk size:\", root['edge_idxs'].chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# writing batches of molecules to a zarr array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a small \"dataset\" of molecules in tensor format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (4745, 3)\n",
      "Shape of a: (4745,)\n",
      "Shape of e: (5607,)\n",
      "Shape of edge_index: (5607, 2)\n",
      "Shape of node_lookup: (500, 2)\n",
      "Shape of edge_lookup: (500, 2)\n"
     ]
    }
   ],
   "source": [
    "n_molecules = 500\n",
    "unbatched_molecules = defaultdict(list)\n",
    "for _ in range(n_molecules):\n",
    "    n_atoms = np.random.randint(5, 15)\n",
    "    n_edges = np.random.randint(n_atoms//2, n_atoms * 2)\n",
    "    x = np.random.randn(n_atoms, 3) # positions\n",
    "    a = np.random.randint(0, 5, size=n_atoms) # atom types\n",
    "    edge_idxs = np.random.randint(0, n_atoms, size=(n_edges, 2)) # edge indicies for bonds\n",
    "    e = np.random.randint(0, 3, size=n_edges) # bond orders\n",
    "\n",
    "    unbatched_molecules['x'].append(x)\n",
    "    unbatched_molecules['a'].append(a)\n",
    "    unbatched_molecules['edge_index'].append(edge_idxs)\n",
    "    unbatched_molecules['e'].append(e)\n",
    "\n",
    "\n",
    "# now batch the molecules together! there are a few steps here\n",
    "\n",
    "# first we need to record the number of nodes and edges in each molecule\n",
    "batch_num_nodes = [x.shape[0] for x in unbatched_molecules['x']]\n",
    "batch_num_edges = [eidxs.shape[0] for eidxs in unbatched_molecules['edge_index']]\n",
    "\n",
    "# convert batch data to numpy arrays\n",
    "batch_num_nodes = np.array(batch_num_nodes)\n",
    "batch_num_edges = np.array(batch_num_edges)\n",
    "\n",
    "# concatenate all the data together\n",
    "x = np.concatenate(unbatched_molecules['x'], axis=0)\n",
    "a = np.concatenate(unbatched_molecules['a'], axis=0)\n",
    "edge_index = np.concatenate(unbatched_molecules['edge_index'], axis=0)\n",
    "e = np.concatenate(unbatched_molecules['e'], axis=0)\n",
    "\n",
    "\n",
    "# create an array of indicies to keep track of the start_idx and end_idx of each molecule's node features\n",
    "node_lookup = np.zeros((n_molecules, 2), dtype=int)\n",
    "node_lookup[:, 1] = np.cumsum(batch_num_nodes, axis=0)\n",
    "node_lookup[1:, 0] = node_lookup[:-1, 1]\n",
    "\n",
    "# create an array of indicies to keep track of the start_idx and end_idx of each molecule's edge features\n",
    "edge_lookup = np.zeros((n_molecules, 2), dtype=int)\n",
    "edge_lookup[:, 1] = np.cumsum(batch_num_edges, axis=0)\n",
    "edge_lookup[1:, 0] = edge_lookup[:-1, 1]\n",
    "\n",
    "# print(\"batch_num_nodes:\", batch_num_nodes)\n",
    "# print(\"batch_num_edges:\", batch_num_edges)\n",
    "print(\"Shape of x:\", x.shape)\n",
    "print(\"Shape of a:\", a.shape)\n",
    "print(\"Shape of e:\", e.shape)\n",
    "print(\"Shape of edge_index:\", edge_index.shape)\n",
    "print(\"Shape of node_lookup:\", node_lookup.shape)\n",
    "print(\"Shape of edge_lookup:\", edge_lookup.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write the molecule dataset to a zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store = zarr.storage.MemoryStore()\n",
    "store = zarr.storage.LocalStore('test_ligand_dataset.zarr')\n",
    "\n",
    "# Create a root group\n",
    "root = zarr.group(store=store)\n",
    "\n",
    "node_data = root.create_group('node_data')\n",
    "edge_data = root.create_group('edge_data')\n",
    "\n",
    "# Store tensors under different keys with specified chunk sizes\n",
    "\n",
    "# some simple heuristics to decide chunk sizes for node and edge data\n",
    "mean_nodes_per_graph = int(np.mean(batch_num_nodes))\n",
    "mean_edges_per_graph = int(np.mean(batch_num_edges))\n",
    "graphs_per_chunk = 50\n",
    "nodes_per_chunk = graphs_per_chunk * mean_nodes_per_graph\n",
    "edges_per_chunk = graphs_per_chunk * mean_edges_per_graph\n",
    "\n",
    "# create arrays for node data\n",
    "node_data.create_array('x', shape=x.shape, chunks=(nodes_per_chunk, 3), dtype=x.dtype)\n",
    "node_data.create_array('a', shape=a.shape, chunks=(nodes_per_chunk,), dtype=a.dtype)\n",
    "\n",
    "# create arrays for edge data\n",
    "edge_data.create_array('e', shape=e.shape, chunks=(edges_per_chunk,), dtype=e.dtype)\n",
    "edge_data.create_array('edge_index', shape=edge_index.shape, chunks=(edges_per_chunk, 2), dtype=edge_index.dtype)\n",
    "\n",
    "# because node_lookup and edge_lookup are relatively small, we may get away with not chunking them\n",
    "node_data.create_array('node_lookup', shape=node_lookup.shape, chunks=node_lookup.shape, dtype=node_lookup.dtype)\n",
    "edge_data.create_array('edge_lookup', shape=edge_lookup.shape, chunks=edge_lookup.shape, dtype=edge_lookup.dtype)\n",
    "\n",
    "# write data to the arrays\n",
    "node_data['x'][:] = x\n",
    "node_data['a'][:] = a\n",
    "edge_data['e'][:] = e\n",
    "edge_data['edge_index'][:] = edge_index\n",
    "node_data['node_lookup'][:] = node_lookup\n",
    "edge_data['edge_lookup'][:] = edge_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize the structure of the zarr store that we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">/</span>\n",
       "├── <span style=\"font-weight: bold\">edge_data</span>\n",
       "│   ├── <span style=\"font-weight: bold\">e</span> (954,) int64\n",
       "│   ├── <span style=\"font-weight: bold\">edge_index</span> (954, 2) int64\n",
       "│   └── <span style=\"font-weight: bold\">edge_lookup</span> (100, 2) int64\n",
       "└── <span style=\"font-weight: bold\">node_data</span>\n",
       "    ├── <span style=\"font-weight: bold\">a</span> (893,) int64\n",
       "    ├── <span style=\"font-weight: bold\">node_lookup</span> (100, 2) int64\n",
       "    └── <span style=\"font-weight: bold\">x</span> (893, 3) float64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m/\u001b[0m\n",
       "├── \u001b[1medge_data\u001b[0m\n",
       "│   ├── \u001b[1me\u001b[0m (954,) int64\n",
       "│   ├── \u001b[1medge_index\u001b[0m (954, 2) int64\n",
       "│   └── \u001b[1medge_lookup\u001b[0m (100, 2) int64\n",
       "└── \u001b[1mnode_data\u001b[0m\n",
       "    ├── \u001b[1ma\u001b[0m (893,) int64\n",
       "    ├── \u001b[1mnode_lookup\u001b[0m (100, 2) int64\n",
       "    └── \u001b[1mx\u001b[0m (893, 3) float64\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type               : Array\n",
       "Zarr format        : 3\n",
       "Data type          : DataType.int64\n",
       "Shape              : (893,)\n",
       "Chunk shape        : (80,)\n",
       "Order              : C\n",
       "Read-only          : False\n",
       "Store type         : MemoryStore\n",
       "Filters            : ()\n",
       "Serializer         : BytesCodec(endian=<Endian.little: 'little'>)\n",
       "Compressors        : (ZstdCodec(level=0, checksum=False),)\n",
       "No. bytes          : 7144 (7.0K)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root['node_data/a'].info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a torch map-style dataset on top of the zarr store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.71753563,  0.1028616 , -0.19695899],\n",
       "        [-0.22229265, -0.21909488,  1.32207747],\n",
       "        [-0.76388048,  1.21722057,  1.51023126],\n",
       "        [-0.42169209, -0.6559013 ,  0.39215927],\n",
       "        [ 0.44029963,  0.87215712,  0.15028246],\n",
       "        [ 0.51902108, -1.85362516, -1.09245339],\n",
       "        [-0.58521468,  1.32320007, -0.05868108]]),\n",
       " array([3, 1, 4, 1, 2, 3, 1]),\n",
       " array([2, 1, 1, 2, 1, 1, 0, 1, 2, 2, 2]),\n",
       " array([[5, 2],\n",
       "        [1, 4],\n",
       "        [6, 5],\n",
       "        [2, 1],\n",
       "        [1, 0],\n",
       "        [0, 4],\n",
       "        [5, 0],\n",
       "        [5, 4],\n",
       "        [0, 3],\n",
       "        [2, 4],\n",
       "        [1, 6]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ZarrDataset(torch_data.Dataset):\n",
    "    def __init__(self, zarr_store):\n",
    "        self.zarr_store = zarr_store\n",
    "\n",
    "        self.n_graphs = self.zarr_store['node_data/node_lookup'].shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_graphs\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # get node and edge data groups from zarr store\n",
    "        node_data = self.zarr_store['node_data']\n",
    "        edge_data = self.zarr_store['edge_data']\n",
    "\n",
    "        # lookup start and end indicies for node and edge data to pull just\n",
    "        # one graph from the full dataset\n",
    "        node_start_idx, node_end_idx = node_data['node_lookup'][idx]\n",
    "        edge_start_idx, edge_end_idx = edge_data['edge_lookup'][idx]\n",
    "\n",
    "        # pull out the data for the graph\n",
    "        x = node_data['x'][node_start_idx:node_end_idx]\n",
    "        a = node_data['a'][node_start_idx:node_end_idx]\n",
    "        e = edge_data['e'][edge_start_idx:edge_end_idx]\n",
    "        edge_idxs = edge_data['edge_index'][edge_start_idx:edge_end_idx]\n",
    "\n",
    "        # TODO: convert to DGL graph\n",
    "\n",
    "        return x, a, e, edge_idxs\n",
    "    \n",
    "dataset = ZarrDataset(root)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coming up next:\n",
    " - [ ] add a dataloader with a custom sampler so that we align our batches with chunks in the zarr store\n",
    " - [ ] make an adaptive dataloader (sampler) that will create batches with a max num nodes or edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing zarr dataset with cached chunk reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/mambaforge/envs/omtra/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from omtra.dataset.dataset import PharmitDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.62326485, -0.87873336, -0.96549612],\n",
       "        [ 0.63350589, -1.30159194,  1.564773  ],\n",
       "        [ 1.51773969, -0.61211175,  0.37788705],\n",
       "        [ 0.77269057, -1.13129397,  0.14709615],\n",
       "        [-0.16707625, -0.87462105, -0.43941419],\n",
       "        [ 0.91228785,  0.04150758, -1.12016163],\n",
       "        [-0.40154383,  0.83246105,  1.52925432],\n",
       "        [ 1.10235684,  1.51754387, -1.6881488 ],\n",
       "        [-0.09701118,  1.23701099, -1.00994055],\n",
       "        [ 0.6342244 , -0.54545091, -0.14252716]]),\n",
       " array([2, 2, 1, 4, 2, 3, 2, 4, 2, 1]),\n",
       " array([2, 2, 0, 2, 1, 0, 0, 1, 0, 1]),\n",
       " array([[9, 1],\n",
       "        [1, 2],\n",
       "        [5, 1],\n",
       "        [1, 6],\n",
       "        [9, 8],\n",
       "        [1, 6],\n",
       "        [9, 7],\n",
       "        [2, 5],\n",
       "        [9, 4],\n",
       "        [8, 1],\n",
       "        [6, 8],\n",
       "        [4, 3],\n",
       "        [4, 2],\n",
       "        [1, 4],\n",
       "        [5, 7],\n",
       "        [1, 7]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PharmitDataset('test_ligand_dataset.zarr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.3100793 , -0.134091  ,  0.59764185],\n",
       "        [ 2.02338129,  1.99602223, -0.90889055],\n",
       "        [ 0.24268334, -0.72793865, -1.0264535 ],\n",
       "        [-0.53326452,  1.20975423, -1.06425972],\n",
       "        [ 0.26202731,  2.23950627,  0.81552695]]),\n",
       " array([1, 4, 0, 0, 0]),\n",
       " array([2, 2, 2, 1, 0]),\n",
       " array([[1, 3],\n",
       "        [3, 2],\n",
       "        [0, 2],\n",
       "        [1, 1],\n",
       "        [0, 4],\n",
       "        [4, 1],\n",
       "        [4, 4],\n",
       "        [0, 1],\n",
       "        [0, 4]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omtra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
